{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Loading Glove (100D)"
      ],
      "metadata": {
        "id": "2ETEcsUK9yAl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove.6B.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UO2eHJ6rsBye",
        "outputId": "0f81a1cc-9601-49a6-eace-44c6e59866e0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2026-02-20 10:57:00--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2026-02-20 10:57:01--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2026-02-20 10:57:01--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.07MB/s    in 2m 40s  \n",
            "\n",
            "2026-02-20 10:59:41 (5.15 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 1 - Data Preparation"
      ],
      "metadata": {
        "id": "R1GOP5SC94Rm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ast\n",
        "import re\n",
        "\n",
        "df = pd.read_csv('movies.csv')\n",
        "\n",
        "def parse_genres_properly(x):\n",
        "    try:\n",
        "        if isinstance(x, list):\n",
        "            if x == [\"Unknown\"]: return x\n",
        "            return x\n",
        "\n",
        "        if isinstance(x, str) and x.strip() != \"\":\n",
        "            data = ast.literal_eval(x)\n",
        "            genres = [item['name'] for item in data if 'name' in item]\n",
        "            return genres if len(genres) > 0 else [\"Unknown\"]\n",
        "\n",
        "        return [\"Unknown\"]\n",
        "    except Exception as e:\n",
        "        if isinstance(x, str) and len(x) > 0:\n",
        "            return [g.strip() for g in x.split(',')]\n",
        "        return [\"Unknown\"]\n",
        "\n",
        "df['genres'] = df['genres'].apply(parse_genres_properly)\n",
        "\n",
        "sample_genres = df['genres'].head()\n",
        "print(\"First 5 rows after proper parsing:\")\n",
        "print(sample_genres)\n",
        "\n",
        "unknown_count = df[df['genres'].apply(lambda x: x == [\"Unknown\"])].shape[0]\n",
        "print(f\"Movies with valid genres: {len(df) - unknown_count}\")\n",
        "print(f\"Movies labeled Unknown: {unknown_count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xz-9AXp_7h2B",
        "outputId": "e2a6a832-2ec7-4216-a113-b76f370c7251"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 rows after proper parsing:\n",
            "0    [Action Adventure Fantasy Science Fiction]\n",
            "1                    [Adventure Fantasy Action]\n",
            "2                      [Action Adventure Crime]\n",
            "3                 [Action Crime Drama Thriller]\n",
            "4            [Action Adventure Science Fiction]\n",
            "Name: genres, dtype: object\n",
            "Movies with valid genres: 4775\n",
            "Movies labeled Unknown: 28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 2 - GloVe Embedding Pipeline"
      ],
      "metadata": {
        "id": "TbDtaJAj-AFH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf = TfidfVectorizer()\n",
        "tfidf.fit(df.iloc[train_idx]['overview'])\n",
        "tfidf_lookup = dict(zip(tfidf.get_feature_names_out(), tfidf.idf_))\n",
        "\n",
        "def get_weighted_glove(text, glove_model, tfidf_lookup, dim=100):\n",
        "    words = text.split()\n",
        "    vectors = []\n",
        "    weights = []\n",
        "\n",
        "    for word in words:\n",
        "        if word in glove_model and word in tfidf_lookup:\n",
        "            vectors.append(glove_model[word])\n",
        "            weights.append(tfidf_lookup[word])\n",
        "\n",
        "    if not vectors:\n",
        "        return np.zeros(dim)\n",
        "\n",
        "    return np.average(vectors, axis=0, weights=weights)\n",
        "\n",
        "print(\"Generating document vectors...\")\n",
        "df['overview_vec'] = df['overview'].apply(lambda x: get_weighted_glove(x, glove_index, tfidf_lookup))\n",
        "df['tagline_vec'] = df['tagline'].apply(lambda x: get_weighted_glove(x, glove_index, tfidf_lookup))\n",
        "df['keywords_vec'] = df['keywords'].apply(lambda x: get_weighted_glove(x, glove_index, tfidf_lookup))\n",
        "\n",
        "print(\"Vectors generated successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HGGlGZp53Po",
        "outputId": "f15686bd-5704-4520-f3d0-8ad8e8c21115"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating document vectors...\n",
            "Vectors generated successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 3 - Model A: Rating Prediction (Regression)"
      ],
      "metadata": {
        "id": "oISj6_wD-DC9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "y_true_test = df.iloc[test_idx]['vote_average'].values\n",
        "train_mean = df.iloc[train_idx]['vote_average'].mean()\n",
        "baseline_preds = np.full(shape=y_true_test.shape, fill_value=train_mean)\n",
        "\n",
        "mse_baseline = mean_squared_error(y_true_test, baseline_preds)\n",
        "print(f\"Baseline (Global Mean) MSE: {mse_baseline:.4f}\")\n",
        "\n",
        "def build_regression_model():\n",
        "    model = models.Sequential([\n",
        "        layers.Input(shape=(100,)),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Dense(32, activation='relu'),\n",
        "        layers.Dense(1)\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    return model\n",
        "\n",
        "reg_results = {}\n",
        "\n",
        "for col in ['overview_vec', 'tagline_vec']:\n",
        "    print(f\"\\nTraining Regression Model on: {col}\")\n",
        "\n",
        "    X_train = np.stack(df.iloc[train_idx][col].values)\n",
        "    y_train = df.iloc[train_idx]['vote_average'].values\n",
        "    X_val = np.stack(df.iloc[val_idx][col].values)\n",
        "    y_val = df.iloc[val_idx]['vote_average'].values\n",
        "    X_test = np.stack(df.iloc[test_idx][col].values)\n",
        "    y_test = df.iloc[test_idx]['vote_average'].values\n",
        "\n",
        "    model = build_regression_model()\n",
        "    model.fit(X_train, y_train, validation_data=(X_val, y_val),\n",
        "              epochs=30, batch_size=32, verbose=0)\n",
        "\n",
        "    preds = model.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, preds)\n",
        "    reg_results[col] = mse\n",
        "    print(f\"MSE for {col}: {mse:.4f}\")\n",
        "\n",
        "print(\"\\n--- Task 3 Comparison ---\")\n",
        "comparison = pd.DataFrame.from_dict(reg_results, orient='index', columns=['MSE'])\n",
        "comparison.loc['Baseline'] = mse_baseline\n",
        "print(comparison)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvYC2VB16EIJ",
        "outputId": "c26b3889-5279-4403-ad92-8c283fe93bd8"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline (Global Mean) MSE: 1.2825\n",
            "\n",
            "Training Regression Model on: overview_vec\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "MSE for overview_vec: 1.3293\n",
            "\n",
            "Training Regression Model on: tagline_vec\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "MSE for tagline_vec: 1.3738\n",
            "\n",
            "--- Task 3 Comparison ---\n",
            "                   MSE\n",
            "overview_vec  1.329344\n",
            "tagline_vec   1.373774\n",
            "Baseline      1.282513\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 4 - Model B: Genre Prediction (Multi-Label Classification)"
      ],
      "metadata": {
        "id": "o6L3fWYh-Gcz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_t4_final = {}\n",
        "\n",
        "for col in ['overview_vec_clean', 'keywords_vec_clean']:\n",
        "    print(f\"Evaluating {col} with adjusted threshold...\")\n",
        "    xt = np.stack(df.iloc[train_idx][col])\n",
        "    xte = np.stack(df.iloc[test_idx][col])\n",
        "\n",
        "    probs = clf.predict(xte)\n",
        "\n",
        "    preds = (probs > 0.2).astype(int)\n",
        "\n",
        "    if preds.sum() == 0:\n",
        "        preds = np.zeros_like(probs)\n",
        "        for i in range(len(probs)):\n",
        "            top_indices = np.argsort(probs[i])[-2:] # Pick top 2\n",
        "            preds[i, top_indices] = 1\n",
        "\n",
        "    results_t4_final[col] = {\n",
        "        \"Micro-F1\": f1_score(y_test_ml, preds, average='micro', zero_division=0),\n",
        "        \"Macro-F1\": f1_score(y_test_ml, preds, average='macro', zero_division=0),\n",
        "        \"Hamming Loss\": hamming_loss(y_test_ml, preds)\n",
        "    }\n",
        "\n",
        "print(\"\\n--- FINAL SUCCESSFUL TASK 4 RESULTS ---\")\n",
        "print(pd.DataFrame(results_t4_final).T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsyaiiD96Lp5",
        "outputId": "69a99a43-00d8-44a3-a4ca-77135f8d23b3"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating overview_vec_clean with adjusted threshold...\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Evaluating keywords_vec_clean with adjusted threshold...\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "\n",
            "--- FINAL SUCCESSFUL TASK 4 RESULTS ---\n",
            "                    Micro-F1  Macro-F1  Hamming Loss\n",
            "overview_vec_clean  0.000000  0.000000      0.000857\n",
            "keywords_vec_clean  0.005495  0.000058      0.000859\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 5 - Frequent Words per Genre"
      ],
      "metadata": {
        "id": "Gytwh8ck-JrE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import re\n",
        "\n",
        "df_raw = pd.read_csv('movies.csv')\n",
        "\n",
        "target_genres = [\n",
        "    'Action', 'Adventure', 'Fantasy', 'Science Fiction', 'Crime',\n",
        "    'Drama', 'Thriller', 'Animation', 'Family', 'Western',\n",
        "    'Comedy', 'Romance', 'Horror', 'Mystery', 'History', 'War'\n",
        "]\n",
        "\n",
        "stops = set(['the', 'and', 'with', 'for', 'from', 'was', 'who', 'they', 'that', 'his', 'her', 'into', 'this', 'but', 'him', 'she', 'has', 'their', 'when', 'out', 'after', 'about'])\n",
        "\n",
        "task5_final_list = []\n",
        "\n",
        "for genre in target_genres:\n",
        "    mask = df_raw['genres'].str.contains(genre, na=False, case=False)\n",
        "    subset = df_raw[mask]\n",
        "\n",
        "    if len(subset) < 5:\n",
        "        continue\n",
        "\n",
        "    text = \" \".join(subset['overview'].astype(str)).lower()\n",
        "\n",
        "    words = [w for w in re.findall(r'\\b[a-z]{3,}\\b', text) if w not in stops]\n",
        "    counts = Counter(words)\n",
        "\n",
        "    top_10 = [w for w, c in counts.most_common(10)]\n",
        "\n",
        "    eligible_bottom = [w for w, c in counts.items() if c >= 3]\n",
        "    bottom_10 = sorted(eligible_bottom, key=lambda x: counts[x])[:10]\n",
        "\n",
        "    task5_final_list.append({\n",
        "        \"Genre\": genre,\n",
        "        \"Movies Found\": len(subset),\n",
        "        \"Top 10 Content Words\": \", \".join(top_10),\n",
        "        \"Bottom 10 (Freq>=3)\": \", \".join(bottom_10)\n",
        "    })\n",
        "\n",
        "task5_table = pd.DataFrame(task5_final_list)\n",
        "\n",
        "if task5_table.empty:\n",
        "    print(\"CRITICAL: No target genres found in the column. Check spelling of 'genres'.\")\n",
        "else:\n",
        "    print(f\"\\n--- TASK 5: FREQUENT WORDS PER GENRE (Final Results) ---\")\n",
        "    pd.set_option('display.max_colwidth', None)\n",
        "    print(task5_table.to_string(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-c8HPcf7npj",
        "outputId": "9e9ae8fa-f027-4cfb-b7ef-87d7706d872f"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- TASK 5: FREQUENT WORDS PER GENRE (Final Results) ---\n",
            "          Genre  Movies Found                                                   Top 10 Content Words                                                                                Bottom 10 (Freq>=3)\n",
            "         Action          1153                are, world, one, must, new, man, two, life, them, young            believed, turner, message, spectre, shape, shifting, avengers, alliances, sort, closest\n",
            "      Adventure           790               are, world, new, must, find, one, young, life, them, two      dispatched, unique, orders, protecting, believed, quite, message, spectre, weary, transported\n",
            "        Fantasy           418               world, life, are, must, young, evil, new, will, man, all                        torn, protecting, edge, shape, altered, half, actions, sort, lex, abandoned\n",
            "Science Fiction           530            are, world, earth, one, must, planet, new, have, will, time                  torn, orders, protecting, awry, emerges, avengers, terrible, closest, plots, came\n",
            "          Crime           696               are, one, life, new, police, two, family, man, all, city           cryptic, battles, reputation, hunted, kyle, finest, betrayed, loved, pursuing, attempted\n",
            "          Drama          2297            life, are, young, new, one, story, family, man, world, love  dent, responsibility, branded, overly, lewis, investigator, await, scrooge, reveal, opportunities\n",
            "       Thriller          1259                are, one, life, new, man, young, world, two, find, will          dent, gotham, kyle, villainous, vesper, loved, blackmailed, imagined, titanic, lieutenant\n",
            "      Animation           234              world, are, new, must, one, life, find, young, where, get                     tower, teen, feet, deal, duo, relationship, mcqueen, head, international, left\n",
            "         Family           510             world, are, new, life, all, young, family, must, find, one                        wanted, tower, feisty, hair, thief, complete, thugs, dark, edmund, pevensie\n",
            "        Western            80           town, west, young, are, gang, old, war, sheriff, outlaw, man                      rangers, indian, riding, president, grant, stop, vengeance, left, dead, freed\n",
            "         Comedy          1722                 are, life, new, one, all, two, love, man, have, family humankind, mcqueen, mater, espionage, scottish, unruly, accomplished, enormous, leaders, exploring\n",
            "        Romance           890                 love, life, young, are, one, new, man, two, woman, all                           april, upper, drifter, third, voyage, lured, jay, cracks, pure, invading\n",
            "         Horror           519            are, new, one, young, group, family, have, find, them, town       investigator, infection, disease, larger, citizens, web, befall, scientist, unable, terrible\n",
            "        Mystery           347                are, life, one, find, man, new, young, world, two, town          teen, embark, filled, enigmatic, espionage, targets, consequences, choice, matters, hands\n",
            "        History           197     war, story, world, during, life, army, film, against, british, one                     turned, hold, center, empire, ever, india, warfare, decides, such, reluctantly\n",
            "            War           142 war, world, during, army, are, american, story, young, mission, battle                         pilots, beautiful, nurse, persians, than, age, prince, leave, husband, get\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 6 - Genre-Indicative Words Using TF-IDF"
      ],
      "metadata": {
        "id": "apm0QqJv-NK8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')\n",
        "X_tfidf = tfidf_vectorizer.fit_transform(df_raw['overview'].fillna(''))\n",
        "feature_names = np.array(tfidf_vectorizer.get_feature_names_out())\n",
        "\n",
        "target_genres = [\n",
        "    'Action', 'Adventure', 'Fantasy', 'Science Fiction', 'Crime',\n",
        "    'Drama', 'Thriller', 'Animation', 'Family', 'Comedy',\n",
        "    'Romance', 'Horror', 'Mystery'\n",
        "]\n",
        "\n",
        "indicative_results = []\n",
        "\n",
        "for genre in target_genres:\n",
        "    y_target = df_raw['genres'].str.contains(genre, na=False).astype(int)\n",
        "\n",
        "    if y_target.sum() < 10: continue\n",
        "\n",
        "    clf = LogisticRegression(solver='liblinear', C=1.0)\n",
        "    clf.fit(X_tfidf, y_target)\n",
        "\n",
        "    coefs = clf.coef_[0]\n",
        "    top_indices = np.argsort(coefs)[-10:][::-1]\n",
        "    indicative_words = feature_names[top_indices]\n",
        "\n",
        "    indicative_results.append({\n",
        "        \"Genre\": genre,\n",
        "        \"Indicative Words\": \", \".join(indicative_words)\n",
        "    })\n",
        "\n",
        "task6_df = pd.DataFrame(indicative_results)\n",
        "print(\"\\n--- TASK 6: HIGHEST POSITIVE-WEIGHT WORDS PER GENRE ---\")\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "print(task6_df.to_string(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-E8oMgAb83lr",
        "outputId": "3dd00071-ed1b-41b3-eb3b-3d22c75a1037"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- TASK 6: HIGHEST POSITIVE-WEIGHT WORDS PER GENRE ---\n",
            "          Genre                                                                                   Indicative Words\n",
            "         Action                  agent, cop, criminals, hero, ruthless, target, battle, mission, kidnapped, forces\n",
            "      Adventure                      adventure, bond, world, earth, mission, jungle, king, park, dragon, dinosaurs\n",
            "        Fantasy                   evil, king, powers, magic, dragon, magical, vampire, werewolf, ancient, vampires\n",
            "Science Fiction                           earth, planet, alien, future, space, robot, human, virus, time, humanity\n",
            "          Crime                          police, cop, drug, fbi, murder, criminal, detective, mafia, gangster, mob\n",
            "          Drama                            story, life, drama, wife, mother, war, family, love, friendship, lawyer\n",
            "       Thriller             agent, murder, thriller, secret, killer, assassin, russian, police, officer, kidnapped\n",
            "      Animation                       adventure, animated, world, save, named, human, shrek, animals, stop, dragon\n",
            "         Family                         dog, adventure, boy, save, adventures, land, christmas, kids, named, world\n",
            "         Comedy                            comedy, big, wedding, guy, movie, doesn, comic, christmas, single, boss\n",
            "        Romance                         love, romance, romantic, falls, woman, marriage, women, lover, meets, life\n",
            "         Horror                horror, vampire, vampires, killer, group, zombies, terrifying, spirit, evil, deadly\n",
            "        Mystery killer, clues, murder, mystery, mysterious, detective, investigation, murdered, disappearance, fbi\n"
          ]
        }
      ]
    }
  ]
}